configfile: "../config/config.yaml"
localrules: all, get_read_groups
# update config based on secondary configuration file
import os
from yaml import safe_load
with open("../config/project.yaml") as project_fh:
	config.update(safe_load(project_fh))

reference_data = config["reference"][config["genome_build"]]

wildcard_constraints:
	sample="\d{10}(?:_ds)?", # samples are exclusively labeled as 10-digit integers so far
	rg="\d+", # samtools labels as integers starting from 0
	group="\d+"

def bams_by_read_group(wildcards):
	read_groups = []
	with open("../scratch/{sample}/{sample}.rgs".format(
		sample=wildcards["sample"])) as rgs_fh:
		for line in rgs_fh:
			read_groups.append(line.split("\t")[1].split(":")[1])
	return ["../scratch/{sample}/{sample}_{rg}.bam".format(
		sample=wildcards["sample"], rg=read_group)
		for read_group in read_groups]

rule get_read_groups:
	"""Extract the set of read groups from a BAM's header."""
	input:
		"../input/bams/{sample}.bam"
	output:
		"../scratch/{sample}/{sample}.rgs"
	conda:
		"envs/bwa_samtools.yaml"
	shell:
		"samtools view -H {input} | grep '^@RG' > {output}"

checkpoint rule split_bam:
	"""Split a BAM by read group."""
	input:
		bam = "../input/bams/{sample}.bam",
		rgs = "../scratch/{sample}/{sample}.rgs"
	output:
		touch("../scratch/{sample}/{sample}.split_bam.done")
	params:
		stdout = "../logs/split_bam/{sample}.out",
		stderr = "../logs/split_bam/{sample}.err"
	conda:
		"envs/bwa_samtools.yaml"
	shell:
		"samtools split -f ../scratch/{wildcards.sample}/"
		"{wildcards.sample}_%#.bam {input.bam}"

rule extract_fastq_from_bam:
	"""Extract the reads from a BAM into an interleaved FASTQ."""
	input:
		flag = "../scratch/{sample}/{sample}.split_bam.done",
		bam = "../scratch/{sample}/{sample}_{rg}.bam"
	output:
		temp("../scratch/{sample}/{sample}_{rg}.fq")
	params:
		stdout = "../logs/extract_fastqs/{sample}_{rg}.out",
		stderr = "../logs/extract_fastqs/{sample}_{rg}.err"
	conda:
		"envs/bwa_samtools.yaml"
	shell:
		"samtools fastq -0 /dev/null {input.bam} > {output}"

rule bwa_align_and_sort:
	"""Align a FASTQ of interleaved reads."""
	input:
		fq = "../scratch/{sample}/{sample}_{rg}.fq",
		rgs = "../scratch/{sample}/{sample}.rgs"
	output:
		temp("../scratch/{sample}/{sample}_reprocessed_{rg}.bam")
	threads: 8
	params:
		stdout = "../logs/bwa/{sample}_{rg}.out",
		stderr = "../logs/bwa/{sample}_{rg}.err"
	conda:
		"envs/bwa_samtools.yaml"
	shell:
		'RG=$(sed -n "$(({wildcards.rg}+1))"'
		"'s:\\t:\\\\t:gp' < {input.rgs}) && "
		"bwa mem "
		"-K 100000000 " # suggested for reproducibility
		"-p " # interleaved reads
		"-Y " # soft clipping of supplementary alignments
		"-t {threads} "
		'-R "$RG" '
		"{reference_data[genome]} "
		"{input.fq} "
		"-Y "
		"| samtools sort -T $TMPDIR "
		"--threads {threads} -O BAM -o {output} -"

def aggregate_read_groups(wildcards):
	split_bams_directory = os.path.dirname(
			checkpoints.split_bam.get(**wildcards).output[0])
	return expand("../scratch/{sample}/{sample}_reprocessed_{rg}.bam",
			sample=wildcards.sample,
			rg=glob_wildcards(
				"{split_bams_directory}/{sample}_{{rg,\d+}}.bam".format(
					split_bams_directory=split_bams_directory,
					sample=wildcards.sample)).rg)

rule mark_duplicates:
	"""Mark PCR duplicates and merge per-RG BAMs."""
	input:
		aggregate_read_groups
	output:
		bam = temp("../scratch/{sample}/{sample}_markdup.bam"),
		metrics = "../output/qc/{sample}_metrics.txt"
	params:
		memory_min = "20G",
		memory_max = "24G", #jvm
		stdout = "../logs/mark_duplicates/{sample}.out",
		stderr = "../logs/mark_duplicates/{sample}.err"
	resources:
		mem = "32gb" #cluster
	conda:
		"envs/picard.yaml"
	shell:
		"picard MarkDuplicates "
		"-Djava.io.tmpdir=$TMPDIR -Xms{params.memory_min} -Xmx{params.memory_max} "
		"--INPUT $(echo {input} | sed 's: : --INPUT :g') "
		"--OUTPUT {output.bam} "
		"--METRICS_FILE {output.metrics} "
		"--OPTICAL_DUPLICATE_PIXEL_DISTANCE 2500 "
		"--VALIDATION_STRINGENCY SILENT"

rule base_recalibration:
	input:
		"../scratch/{sample}/{sample}_markdup.bam"
	output:
		"../output/recal_tables/{sample}_recal.table"
	params:
		memory = "24G", #jvm
		stdout = "../logs/base_recalibration/{sample}.out",
		stderr = "../logs/base_recalibration/{sample}.err"
	resources:
		mem = "32gb" #cluster
	conda:
		"envs/gatk.yaml"
	shell:
		"gatk "
		'--java-options "-Djava.io.tmpdir=$TMPDIR -Xms{params.memory}" '
		"BaseRecalibrator "
		"-R {reference_data[genome]} "
		"-I {input} "
		"--known-sites {reference_data[dbsnp]} "
		"--known-sites {reference_data[indel_mills]} "
		"--known-sites {reference_data[indel_known]} "
		"-O {output}"

rule apply_BQSR:
	input:
		bam = "../scratch/{sample}/{sample}_markdup.bam",
		recal_table = "../output/recal_tables/{sample}_recal.table"
	output:
		bam = "../output/bams/{sample}.bam",
		bai = "../output/bams/{sample}.bai"
	params:
		memory = "24G", #jvm
		stdout = "../logs/apply_BQSR/{sample}.out",
		stderr = "../logs/apply_BQSR/{sample}.err"
	resources:
		mem = "32gb", #cluster
		mail = "ae" # send an email when finished as this is the last step
	conda:
		"envs/gatk.yaml"
	shell:
		"gatk "
		'--java-options "-Djava.io.tmpdir=$TMPDIR -Xms{params.memory}" '
		"ApplyBQSR "
		"-R {reference_data[genome]} "
		"-I {input.bam} "
		"-O {output.bam} "
		"-bqsr {input.recal_table} "
		"--static-quantized-quals 10 "
		"--static-quantized-quals 20 "
		"--static-quantized-quals 30 "
		"--add-output-sam-program-record "
		"--create-output-bam-md5 "

rule haplotype_caller:
	input:
		bam = "../output/bams/{sample}.bam",
		interval_file = "../resources/intervals/intervalfile_{group}.list" # parallelization - currently 120x
	output:
		"../scratch/{sample}/{sample}_{group}.g.vcf.gz"
	params:
		memory = "6G",
		stdout = "../logs/haplotype_caller/{sample}_{group}.out",
		stderr = "../logs/haplotype_caller/{sample}_{group}.err"
	resources:
		mem = "12gb"
	conda:
		"envs/gatk.yaml"
	shell:
		"gatk "
		'--java-options "-Djava.io.tmpdir=$TMPDIR -Xms{params.memory}" '
		"HaplotypeCaller "
		"-R {reference_data[genome]} "
		"-I {input.bam} "
		"-L {input.interval_file} "
		"-O {output} "
		"-GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 50 "
		"-GQB 60 -GQB 70 -GQB 80 -GQB 90 "
		"-ERC GVCF "
		"-G StandardAnnotation "
		"-G AS_StandardAnnotation "
		"-G StandardHCAnnotation "

rule merge_gvcfs:
	input:
		expand("../scratch/{sample}/{sample}_{group}.g.vcf.gz",
				sample=wildcards.sample,
				group=sorted(
					[int(value) for value in glob_wildcards(
					"../resources/intervals/intervalfile_{group,\d+}.list").group]))
	output:
		"../output/gvcfs/{sample}.g.vcf.gz"
	params:
		memory = "12G",
		stdout = "../logs/merge_gvcfs/{sample}.out",
		stderr = "../logs/merge_vcfs/{sample}.err"
	conda:
		"envs/picard.yaml"
	shell:
		"picard MergeVcfs "
		"-Djava.io.tmpdir=$TMPDIR -Xmx{params.memory} "
		"--INPUT $(echo {input} | sed 's: : --INPUT :g') "
		"--output {output}"
